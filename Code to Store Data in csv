import requests
from bs4 import BeautifulSoup
import csv

def scrape_link(link):
    try:
        # Access the web page
        response = requests.get(link)
        response.raise_for_status()  # Raise an HTTPError for bad responses (status codes 4xx or 5xx)
        
        if response.status_code == 200:
            html_content = response.content
            soup = BeautifulSoup(html_content, 'html.parser')

            # Extract relevant information
            text_content = soup.get_text()
            links = [a['href'] for a in soup.find_all('a', href=True)]
            images = [img['src'] for img in soup.find_all('img', src=True)]

            # Write the scraped data to a CSV file
            with open('scraped_data.csv', 'a', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Link', 'Title', 'Text Content', 'Links', 'Image URLs']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                # Write headers if the file is empty
                if csvfile.tell() == 0:
                    writer.writeheader()

                # Write the data to the CSV file
                writer.writerow({
                    'Link': link,
                    'Title': soup.title.text,
                    'Text Content': text_content,
                    'Links': ', '.join(links),
                    'Image URLs': ', '.join(images)
                })
        else:
            print("Failed to access:", link)
    except requests.exceptions.RequestException as e:
        print("Error accessing:", link)
        print("Exception:", e)

# List of links
links = [
   "https://products.basf.com/global/en/ci/n-vinyl-2-pyrrolidone.html",
    "https://pubchem.ncbi.nlm.nih.gov/compound/N-Vinyl-2-pyrrolidone",
    "https://www.shokubai.co.jp/en/products/detail/nvp/",
    "https://pubchem.ncbi.nlm.nih.gov/compound/N-Vinyl-2-pyrrolidone",
    "https://www.sciencedirect.com/topics/pharmacology-toxicology-and-pharmaceutical-science/1-vinyl-2-pyrrolidinone",
    "https://www.ncbi.nlm.nih.gov/books/NBK498761/#:~:text=It%20is%20used%20in%20the,the%20synthesis%20of%20phenolic%20resins",
    "https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/polyvinylpyrrolidone#:~:text=PVP%20added%20to%20iodine%20forms,trade%20name%20Betadine%20and%20Pyodine",
    "https://www.shokubai.co.jp/en/products/detail/nvp/#:~:text=N%2Dvinylpyrrolidone%20is%20a%20nonionic,monomer%20with%20the%20following%20features.&text=N%2Dvinylpyrrolidone%20is%20used%20as,of%20reactivity%20with%20UV%20irradiation",
    "https://adhesives.specialchem.com/product/m-basf-n-vinyl-pyrrolidone-nvp",
    "https://www.welinkschem.com/nvp-n-vinyl-pyrrolidone/",
    "https://pubs.rsc.org/en/content/articlelanding/2019/py/c8py01459k",
    "https://www.science.gov/topicpages/n/n-vinyl+pyrrolidone+nvp",
    "https://shdexiang.en.made-in-china.com/product/tXfQDioPsKVn/China-N-Vinylpyrrolidone-CAS-No-88-12-0-C6h9no.html",
    "https://www.cphi-online.com/nvp-n-vinylpyrrolidone-prod1288298.html",
    "https://www.mdpi.com/2073-4360/11/6/1079"
]

# Scrape data from each link and store it in a CSV file
for link in links:
    scrape_link(link)
